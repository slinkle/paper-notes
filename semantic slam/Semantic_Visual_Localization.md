# Semantic Visual Localization

* 提取3D语义特征，既能应对季节，光照等变化，又能应对较大的视角变化
* 生成模型提取特征，非判别模型
* 自监督学习，无需人工标注
* 泛化能力强，应用到新的数据集上无需重新训练
* 大体思路是训练一个能根据部分地图恢复完整语义地图的生成模型，其变分自编码部分的隐含层为提取的特征

<div align="center">
<img src="https://i.loli.net/2018/06/08/5b19dfb5bca44.png"  />
</div>

## 具体方法

color images 和对应 depth images 组成图片集 I={Ii},相应的相机位姿组成 P={Pi}。给出一个子集 Id 和 Pd，在预处理阶段先创建一个全局3D语义地图Md。当给出一张或多张查询图片Iq，我们通过构建一个局部3D语义地图Mq与全局地图Md进行3D-3D的匹配来确定欲查询的位姿Pq。

一般的低层次的几何特征会随视角和光照的变化而发生改变，而高层次的场景语义特征对这些变化是具有不变性的。本文的目的就是提取这样的语义特征用于定位，具体工作分为以下三个步骤：

1. 离线步骤：训练一个能根据部分地图恢复完整地图的生成模型，达到提取特征的目的
2. 用提取到的特征在地图与地图之间做匹配
3. 匹配就对应到了一个位姿估计
